# -*- coding: utf-8 -*-
"""Car_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10_GE0luSLEFBn0UrH1S2cCr7O0rnFjzb

# **Car Prediction Analysis**

🧩**Dataset:**

This dataset contains some information about used cars listed  
like Car_Age, KM_Driven, Fuel_Type, Transmission, Mileage, Engine, Owner_Type, and Selling_Price (target).

🎯 **Objective**:
Predict the selling price of a used car based on its specifications. This project will help you practice regression modeling, feature engineering, and evaluation metrics for continuous predictions.

**Steps involves:**

* Data understanding
* Data cleaning
* Outlier detection
* Feature engineering
* Data visualization
* Model selection and training
* Model evaluation
* Prediction

**project outlook**

    • 1. Data Understanding:  Explore dataset structure and identify missing or incorrect values.

    • 2. Data Cleaning: Handle missing values, remove units from numeric columns (e.g., km/l), and remove duplicates.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
    
data = pd.read_csv('car_streamlit/Car details v3 (1).csv' ,encoding= 'latin 1')
df = pd.DataFrame(data)
# display(df.head())

print(df.isnull().sum())

#spliting brand name from name column

def pyfunction():
    data = pd.read_csv('car_streamlit/Car details v3 (1).csv' ,encoding= 'latin 1')
    df = pd.DataFrame(data)
    df['brand'] = df['name'].str.split().str[0]
    brand = df.groupby('brand')['name'].count()
    print(brand) 
    df['mileage'] = df['mileage'].astype(str).str.extract(r'(\d+\.\d+|\d+)').astype(float)
    df['mileage'] = df['mileage'].astype(float)

    # df['mileage'] = df['mileage'].str.extract('(\d+\.\d+|\d+)').astype(float)
    df['engine'] = df['engine'].str.extract('(\d+)').astype(float)
    df['max_power'] = df['max_power'].str.extract('(\d+\.\d+|\d+)').astype(float)
    df['seats'] = df['seats'].astype(float)
    df['torque'] = df['torque'].str.extract('(\d+\.\d+|\d+)').astype(float)
    # fill the millage by brand mean value
    df['mileage'] = df.groupby('brand')['mileage'].transform(lambda x: x.fillna(x.mean()))
    df['engine'] = df.groupby('brand')['engine'].transform(lambda x: x.fillna(x.mean()))
    #change str into float
    df['torque']= df['torque'].fillna(df['torque'].mean())
    df['max_power'] = df['max_power'].fillna(df['max_power'].mean())
    df['seats']=df['seats'].fillna(df['seats'].mean())

    df.fillna(0, inplace=True)
    print(df.isnull().sum())
    # display(df.head()) # type: ignore 
  
    return df

def feature_engineering():
    
    price_per_km = df['selling_price'] / df['km_driven']
    df['price_per_km'] = price_per_km
    print(df['price_per_km'].head())

    yearcar= df['year'].unique()
    print(yearcar)

    age_category = []
    for year in df['year']:
        if year <= 2000:
            age_category.append('Old')
        elif year <= 2010:
            age_category.append('Mid')
        else:
            age_category.append('New')

    df['age_category'] = age_category


    age_year = df.groupby('age_category')['year']
    vg = pd.DataFrame(age_year.unique())
    print(vg)

    sns.countplot(data=df,x=('age_category'))
    
    return age_year,age_category,vg

    """5. Encoding: Convert categorical features using OneHotEncoder or LabelEncoder.
    6. Feature Scaling: Apply scaling to numeric features to ensure model stability.
    """

def labelencoder():
    
    #onehot label encoder
    from sklearn.preprocessing import OneHotEncoder
    from sklearn.preprocessing import LabelEncoder
    
    seller_type = df['seller_type'].unique()
    print("seller type : \n ",seller_type)

    owner = df['owner'].unique()
    print("ownership type : \n ",owner)

    fuel = df['fuel'].unique()
    print("fuel \n",fuel)

    transmission = df['transmission'].unique()
    print("transmission \n",transmission)

    # print(df.isnull().sum())
    #transmission encoding Manual -0 , Automatic -1
    df['transmission_encode'] = df['transmission'].map({'Manual': 0, 'Automatic': 1})
    df['transmission'] = LabelEncoder().fit_transform(df['transmission'])
    df['fuel'] = LabelEncoder().fit_transform(df['fuel'])
    df['owner'] = LabelEncoder().fit_transform(df['owner'])
    # print(df['transmission'].count())
    #seller vs transmission type

    total_trans = df.groupby('seller_type')['transmission'].value_counts()
    print(total_trans)
    total_owner = df.groupby('seller_type')['owner'].value_counts()
    print(total_owner)

    print(df['transmission_encode'].head())

    """**visuvalizaton**"""

    fig , axes = plt.subplots(2,2, figsize=(10,10))
    sns.countplot(data=df,x=('seller_type'),hue='transmission',ax=axes[0,0])
    sns.countplot(data=df,x=('seller_type'),hue='owner',ax=axes[0,1])
    sns.countplot(data=df,x=('fuel'),hue='transmission',ax=axes[1,0])
    sns.histplot(df['mileage'],ax=axes[1,1])

    """***Model Scaling***"""
def model_scaling():
    
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.preprocessing import StandardScaler
    from sklearn.preprocessing import RobustScaler
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import mean_squared_error, r2_score

    # df.info()

    x = df[['km_driven','fuel','transmission','engine','price_per_km','mileage','max_power','torque']]
    y = df['selling_price']

    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)

    scaler = MinMaxScaler()
    x_train_scaled = scaler.fit_transform(x_train)
    x_test_scaled = scaler.transform(x_test)

    print(x_train_scaled)
    print(x_test_scaled)
    print(x_test.shape)
    print(y_train.shape)
    print(y_test.shape)
    print(x_train.shape)

    """7. Model Building: Train at least two regression models (e.g., Linear Regression, Random Forest Regressor).

    8. Model Evaluation: Use metrics such as Mean Squared Error (MSE), Mean Absolute Error (MAE), and R² Score.
    """

    
    #linear,random,forest
    from sklearn.linear_model import LinearRegression,LogisticRegression
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error
    # from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc
    # from sklearn.tree import DecisionTreeClassifier
    # from sklearn.ensemble import RandomForestClassifier

    # Linear Regression

    model = LinearRegression()
    model.fit(x_train_scaled,y_train)
    y_pred = model.predict(x_test_scaled)
    print(y_pred)
    print(y_test)
    print("y_pred",y_pred.shape)
    print("y_test",y_test.shape)
    print("x_test",x_test.shape)
    print(x_train.shape)

    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)

    print("Mean Squared Error:", mse)
    print("R-squared:", r2)
    print("Mean Absolute Error:", mae)

    """Random Forest Regression"""

    #random forest regression
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error

    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)

    scaler = StandardScaler()
    x_train_scaled = scaler.fit_transform(x_train)
    x_test_scaled = scaler.transform(x_test)
    model = RandomForestRegressor()
    model.fit(x_train_scaled,y_train)
    y_pred = model.predict(x_test_scaled)

    print("y_pred",y_pred.shape)
    print("y_test",y_test.shape)
    print("x_test",x_test.shape)
    print(x_train.shape)

    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)

    print("Mean Squared Error:", mse)
    print("R-squared:", r2)
    print("Mean Absolute Error:", mae)

    """9. Hyperparameter Tuning: Optimize model parameters using GridSearchCV."""

    # cross validation
    from sklearn.model_selection import GridSearchCV
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error
    from sklearn.model_selection import cross_val_score
    from sklearn.model_selection import RandomizedSearchCV
    from scipy.stats import randint
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.metrics import classification_report
    from sklearn.metrics import confusion_matrix

    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)

    scaler = StandardScaler()
    x_train_scaled = scaler.fit_transform(x_train)
    x_test_scaled = scaler.transform(x_test)
    #---CROSS Validation ---#
    model = DecisionTreeClassifier()
    cv_scores = cross_val_score(model, x_train_scaled, y_train, cv=5)
    print("Cross-Validation Scores:", cv_scores)
    print("Mean CV Score:", np.mean(cv_scores))

    #------GRID SERACH ----#
    param_grid = {
        'max_depth': [None, 10, 20, 30],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    }

    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)
    grid_search.fit(x_train_scaled, y_train)

    print("Best Parameters:", grid_search.best_params_)
    print("Best Score:", grid_search.best_score_)

    # ---- RANDOMIZEDSEARCHCV ----#


    model = DecisionTreeClassifier()

    param_dist = {'max_depth': randint(2, 10),
                'min_samples_split': randint(2, 10)}

    random_search = RandomizedSearchCV(model, param_distributions=param_dist,
                                    n_iter=8, cv=5, random_state=42)
    random_search.fit(x, y)

    print("\n3️⃣ RANDOMIZEDSEARCHCV RESULTS:")
    print("Best Parameters:", random_search.best_params_)
    print("Best Accuracy:", round(random_search.best_score_, 2))

    #--- TRACKING TUNING RESULTS ---#

    results_df = pd.DataFrame(grid_search.cv_results_)
    print("\n4️⃣ TRACKING TUNING RESULTS (Top 5):")
    print(results_df[['params', 'mean_test_score']].sort_values(by='mean_test_score', ascending=False).head(5))


    model = LogisticRegression(solver="liblinear")
    model.fit(x_train, y_train)

    # Probabilities of being class 1
    probs = model.predict_proba(x_test)[:, 1]

    # Default threshold = 0.5
    preds_05 = (probs >= 0.5)

    # Custom threshold = 0.3
    preds_03 = (probs >= 0.3)

    # print("Threshold = 0.5:\n", classification_report(y_pred ,preds_05, zero_division=0))
    # print("Threshold = 0.3:\n", classification_report(y_pred ,preds_03, zero_division=0))


    predictions = model.predict(x_test)
    print("Predictions:", predictions)

    # Confusion Matrix
    confusion_mat = confusion_matrix(y_test, predictions)
    print("Confusion Matrix:\n", confusion_mat)

    #linear,random,forest
    from sklearn.linear_model import LinearRegression,LogisticRegression
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
    # from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
    # from sklearn.tree import DecisionTreeClassifier
    # from sklearn.ensemble import RandomForestClassifier

    # Linear Regression
    models = {
        "Linear Regression": LinearRegression(),
        "Random Forest": RandomForestRegressor(random_state=42)
    }

    results = []

    for name, model in models.items():
        model.fit(x_train, y_train)
        y_pred = model.predict(x_test)

        results.append({
            "Model": name,
            "Mean Squared Error": mean_squared_error(y_test, y_pred),
            "R-squared": r2_score(y_test, y_pred),
            "Mean Absolute Error": mean_absolute_error(y_test, y_pred)

        })

    df_results = pd.DataFrame(results)
    print("\n📊 MODEL SELECTION RESULTS (Before Tuning):")
    print(df_results)

    """10. Model Interpretation: Identify the features that most influence car prices."""

    # Model Interpretation: Feature Importance for Random Forest
    model = RandomForestRegressor(random_state=42)
    model.fit(x_train, y_train)

    feature_importances = pd.Series(model.feature_importances_, index=x.columns)
    sorted_feature_importances = feature_importances.sort_values(ascending=False)

    plt.figure(figsize=(10, 6))
    sorted_feature_importances.plot(kind='bar')
    plt.title('Feature Importances (Random Forest)')
    plt.ylabel('Importance')
    plt.show()

    print("\nFeature Importances (Random Forest):")
    print(sorted_feature_importances)
    
    return df,data

def kpi():
  #kpi useage
    def shorten_number_builtin(num):
        """
        Converts a number to a human-readable short string (e.g., 5187873253 -> '5.19B').
        This uses ONLY built-in Python features (no external libraries).
        """
        # Ensure the input is a float for accurate division
        num = float(num)
        
        # Define the magnitude thresholds and their suffixes
        # (10^0, 10^3, 10^6, 10^9, 10^12)
        suffixes = ['', 'K', 'M', 'B', 'T']
        
        # Loop through the powers of 10 in descending order
        # Starts at 10^12 (T) and works down to 10^0
        for i in range(len(suffixes) - 1, -1, -1):
            power = 10**(i * 3)
            
            # Check if the number is large enough for the current suffix
            if abs(num) >= power:
                # Format the number: Divide, round to 2 decimal places, and append suffix
                short_num = round(num / power, 2)
                return f"{short_num}{suffixes[i]}"
                
        # If the number is < 1000, return it as is
        return str(num)

    # --- Example Usage ---
    original_number = 5187873253
    short_kpi = shorten_number_builtin(original_number)

    print(f"Original: {original_number}")
    print(f"Short Format (KPI): {short_kpi}")
    # Output: Short Format (KPI): 5.19B

    total_sales = df['selling_price'].sum()
    print("Total Sales:", total_sales)

    total_sales1 = shorten_number_builtin(total_sales)
    print("Total Sales:", total_sales1)

    total_cars = len(df)
    print("Total Cars:", total_cars)

    average_price = df['selling_price'].mean()
    print("Average Price:", average_price)

    average_price1 = shorten_number_builtin(average_price)
    print("Average Price:", average_price1)
    
    df['brand'] = df['name'].str.split().str[0]
    # brand = df.groupby('brand')['name'].count()
    
    total_brand = df['brand'].nunique()
    print("Total Brands:", total_brand)

    sales_by_year = df.groupby('year')['selling_price'].sum()
    # print("\nSales by Year:")
    # print(sales_by_year)
    years_count = df['year'].nunique()
    print("Number of Years:", years_count)

    # profit percentage of last 5 years 
    profit_per = sales_by_year[::-3]
    print(profit_per)

    # precentage of these sales 
    percentage_sales = (profit_per / total_sales) * 100
    print(percentage_sales)

    # diff of percentage
    diff_percentage = percentage_sales.diff()
    print(diff_percentage) 
    
    return total_sales1,total_brand,sales_by_year,percentage_sales,diff_percentage,profit_per
 
def yearly_profit():
    total_sales1, total_brand, sales_by_year, percentage_sales, diff_percentage, profit_per = kpi()
    # Calculate year-over-year percentage change in sales
    sales_by_year_percentage_change = sales_by_year.pct_change() * 100

    # Replace NaN with 0 for the first year
    sales_by_year_percentage_change.fillna(0, inplace=True)

    # Display profit/loss in a positive way for all years
    print("\nYear-over-Year Sales Change (%):")
    for year, change in sales_by_year_percentage_change.items():
        if change >= 0:
            print(f"Year {year}: +{change:.2f}% (Profit)")
        else:
            print(f"Year {year}: {abs(change):.2f}% (Loss)")
            
            

    # Display profit/loss in a positive way for the last 10 years
    print("\nYear-over-Year Sales Change (%) for Last 10 Years:")
    last_10_years_sales_change = sales_by_year_percentage_change.tail(10)
    for year, change in last_10_years_sales_change.items():
        if change >= 0:
            print(f"Year {year}: +{change:.2f}% (Profit)")
        else:
            print(f"Year {year}: {abs(change):.2f}% (Loss)")


    data2 = pd.DataFrame(last_10_years_sales_change)
    # calculate + value only percentage data2
    profit_percent = data2[data2['selling_price'] > 0].sum().iloc[0].round(0)
    # print(profit_percent.iloc[0])

    precent = profit_percent / data2.sum() * 100
    print("Percentage  of Years with Profit/Loss in the last 10 Years:", str(precent.round(0).iloc[0]))
    return profit_percent,last_10_years_sales_change,sales_by_year_percentage_change
